{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Tgwt8KeTcis"
   },
   "source": [
    "## Lab 8 Semantic Analysis Part 2\n",
    "\n",
    "In this notebok, you learn how to create an LSTM model with multiple layers, preprocess the text data, train the model, and evaluate its performance in the context of sentiment analysis. You will learn how to build an LSTM model to analyse the reviews in the dataset and classify these reviews as positive or negative sentiment. \n",
    "* Dataset used: the IMDB movie review dataset which is available in tensorflow keras datasets. The dataset contains 50,000 movie reviews, divided into 25,000 for training and 25,000 for testing, labelled as positive or negative.\n",
    "* Machine learning platform: TensorFlow and Keras library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3121,
     "status": "ok",
     "timestamp": 1691056219784,
     "user": {
      "displayName": "Mingshan Jia",
      "userId": "05917314885843876736"
     },
     "user_tz": -600
    },
    "id": "tVhha-zHqoPv",
    "outputId": "9cf1d478-2cb1-4b89-d718-a9ca68d00abe"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "max_features = 20000  # Consider only the top 50,000 words from the dataset\n",
    "maxlen = 500 # Truncate or pad sequences to this length\n",
    "batch_size = 32  # Number of samples processed before the model is updated\n",
    "\n",
    "print('Loading data...')\n",
    "(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(input_train), 'train sequences')\n",
    "print(len(input_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 401,
     "status": "ok",
     "timestamp": 1691056229046,
     "user": {
      "displayName": "Mingshan Jia",
      "userId": "05917314885843876736"
     },
     "user_tz": -600
    },
    "id": "htX1oG0tJ_UX",
    "outputId": "c8cd8745-8150-4289-ab94-c359b53c084f"
   },
   "outputs": [],
   "source": [
    "print(\"Before padding:\")\n",
    "print(\"Length of the first training sequence: \", len(input_train[0]))\n",
    "print(\"First training sequence: \", input_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "executionInfo": {
     "elapsed": 684,
     "status": "ok",
     "timestamp": 1691056231652,
     "user": {
      "displayName": "Mingshan Jia",
      "userId": "05917314885843876736"
     },
     "user_tz": -600
    },
    "id": "VHreaKZYKklD",
    "outputId": "80c61821-99a2-41cb-c0dc-0b2370a0fd95"
   },
   "outputs": [],
   "source": [
    "# Decode the content to words\n",
    "word_index = imdb.get_word_index()\n",
    "def decode_review(review):\n",
    "    reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in review])\n",
    "\n",
    "decode_review(input_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1691056231653,
     "user": {
      "displayName": "Mingshan Jia",
      "userId": "05917314885843876736"
     },
     "user_tz": -600
    },
    "id": "Lq-f3hSmPJVV",
    "outputId": "e3469fe1-569b-413e-fdbe-830023dcbcbb"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get lengths of the reviews\n",
    "review_lengths = [len(review) for review in input_train]\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(review_lengths, bins=30)\n",
    "plt.title('Histogram of Review Lengths')\n",
    "plt.xlabel('Review Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1331,
     "status": "ok",
     "timestamp": 1691056233451,
     "user": {
      "displayName": "Mingshan Jia",
      "userId": "05917314885843876736"
     },
     "user_tz": -600
    },
    "id": "uLFWwkGYPF5Y",
    "outputId": "82ce11a5-bbac-4b03-f3d8-9f04d4fdba32"
   },
   "outputs": [],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "input_train = sequence.pad_sequences(input_train, maxlen=maxlen)\n",
    "input_test = sequence.pad_sequences(input_test, maxlen=maxlen)\n",
    "\n",
    "print('input_train shape:', input_train.shape)\n",
    "print('input_test shape:', input_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1691056233454,
     "user": {
      "displayName": "Mingshan Jia",
      "userId": "05917314885843876736"
     },
     "user_tz": -600
    },
    "id": "BWCL4jPKL1Sd",
    "outputId": "63f048ba-3628-45b0-8369-c327cc3b2f2c"
   },
   "outputs": [],
   "source": [
    "# Print some sequences after padding\n",
    "print(\"\\nAfter padding:\")\n",
    "print(\"Length of the first training sequence: \", len(input_train[0]))\n",
    "print(\"First training sequence: \", input_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 152585,
     "status": "ok",
     "timestamp": 1691056386453,
     "user": {
      "displayName": "Mingshan Jia",
      "userId": "05917314885843876736"
     },
     "user_tz": -600
    },
    "id": "QOOolRyxrjSY",
    "outputId": "45896d26-b64f-4c5e-c1a0-fa91a13ddd65"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The model will consist of an embedding layer to convert word indices into dense vectors, \n",
    "followed by an LSTM layer, and then a fully connected layer to produce the final sentiment probabilities.\n",
    "'''\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import LSTM, Embedding, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['acc'])\n",
    "history = model.fit(input_train, y_train,\n",
    "epochs=9,\n",
    "batch_size=128,\n",
    "validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "executionInfo": {
     "elapsed": 1146,
     "status": "ok",
     "timestamp": 1691056387569,
     "user": {
      "displayName": "Mingshan Jia",
      "userId": "05917314885843876736"
     },
     "user_tz": -600
    },
    "id": "yrW57hd1r8wN",
    "outputId": "674ab339-b23e-436c-b995-c3ec695f1608"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(epochs, acc, 'b', label='Training acc', linewidth=2)\n",
    "ax1.plot(epochs, val_acc, 'r', label='Validation acc', linewidth=2)\n",
    "ax1.set_title('Training and Validation Accuracy')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(epochs, loss, 'b', label='Training loss', linewidth=2)\n",
    "ax2.plot(epochs, val_loss, 'r', label='Validation loss', linewidth=2)\n",
    "ax2.set_title('Training and Validation Loss')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10341,
     "status": "ok",
     "timestamp": 1691056400338,
     "user": {
      "displayName": "Mingshan Jia",
      "userId": "05917314885843876736"
     },
     "user_tz": -600
    },
    "id": "uaAGiIw0zrV0",
    "outputId": "66ef437f-3300-4ed6-d0b0-658a3558f6a3"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(input_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1016,
     "status": "ok",
     "timestamp": 1691057962815,
     "user": {
      "displayName": "Mingshan Jia",
      "userId": "05917314885843876736"
     },
     "user_tz": -600
    },
    "id": "ddZR1JJzuOz6",
    "outputId": "8e25dfa8-554e-481c-9b25-1a16fea8b96a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def decode_review(review):\n",
    "    # Remove any padding tokens\n",
    "    review = [token for token in review if token != 0]\n",
    "    reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in review])\n",
    "\n",
    "for i in range(100, 110):\n",
    "    # Convert the i-th review to a numpy array and expand its dimensions\n",
    "    review = np.expand_dims(input_test[i], axis=0)\n",
    "\n",
    "    # Get the prediction for the i-th review\n",
    "    prediction = model.predict(review)[0][0]\n",
    "    predicted_label = \"positive\" if prediction > 0.5 else \"negative\"\n",
    "\n",
    "    # Get the actual label\n",
    "    actual_label = \"positive\" if y_train[i] == 1 else \"negative\"\n",
    "\n",
    "    # Print the original review, the predicted result, and the actual label\n",
    "    print(f\"Review {i+1}:\")\n",
    "    print(decode_review(input_test[i]))\n",
    "    print(\"Predicted sentiment: \", predicted_label)\n",
    "    print(\"Actual sentiment: \", actual_label)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1691056388949,
     "user": {
      "displayName": "Mingshan Jia",
      "userId": "05917314885843876736"
     },
     "user_tz": -600
    },
    "id": "BjX4dWMPPpMC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
